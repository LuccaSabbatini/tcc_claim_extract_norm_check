{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b529140b",
   "metadata": {},
   "source": [
    "# 02 - Fact Checking\n",
    "\n",
    "This notebook is responsible for performing the fact-checking task on the claims that were extracted and normalized in the previous notebook. It loads the datasets generated previously, creates batches of jobs for fact-checking, and processes these jobs so that the LLM can classify the claims as true or false."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "871cee1f",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "35653a04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Native\n",
    "import logging\n",
    "\n",
    "# Third-party\n",
    "import torch\n",
    "import sklearn\n",
    "import evaluate\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from emoji import demojize\n",
    "from datasets import load_dataset\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    DataCollatorWithPadding,\n",
    "    TrainingArguments,\n",
    "\t\tTrainer,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81d77615",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "60919a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO, format=\"%(asctime)s - %(levelname)s - %(message)s\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "519f4488",
   "metadata": {},
   "source": [
    "### Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c48ef19e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset Constants\n",
    "DATASET_NAME = \"faketweetbr\"\n",
    "DATASET_TASK = \"original\"\n",
    "DATASET_PROCESS_ID = \"\"\n",
    "\n",
    "# Paths Constants\n",
    "DATA_PATH = f\"../data/{DATASET_NAME}/{DATASET_TASK}/{DATASET_PROCESS_ID + \"/\" if DATASET_PROCESS_ID else \"\"}\" # Last path corresponds to the task that original data (i.e., original, claim_extraction, claim_normalization).\n",
    "OUTPUT_PATH = f\"../data/{DATASET_NAME}/results/{DATASET_TASK}/{DATASET_PROCESS_ID + \"/\" if DATASET_PROCESS_ID else \"\"}\"\n",
    "\n",
    "# Model Constants\n",
    "MODEL_NAME = \"neuralmind/bert-large-portuguese-cased\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d188e9a",
   "metadata": {},
   "source": [
    "### Verify GPU Availability and Info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "129f941b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-10 10:47:54,320 - INFO - Torch CUDA available: True\n",
      "2025-11-10 10:47:54,321 - INFO - Torch CUDA version: 12.1\n",
      "2025-11-10 10:47:54,322 - INFO - GPU: NVIDIA GeForce RTX 4060 Ti\n"
     ]
    }
   ],
   "source": [
    "logging.info(f\"Torch CUDA available: {torch.cuda.is_available()}\")\n",
    "\n",
    "# Log GPU info\n",
    "if torch.cuda.is_available():\n",
    "    logging.info(f\"Torch CUDA version: {torch.version.cuda}\")\n",
    "    logging.info(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "else:\n",
    "    logging.info(\"No GPU found, training on CPU\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0fef088",
   "metadata": {},
   "source": [
    "### Load and Setup Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0032615f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'AutoTokenizer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m tokenizer = \u001b[43mAutoTokenizer\u001b[49m.from_pretrained(\n\u001b[32m      2\u001b[39m     MODEL_NAME, do_lower_case=\u001b[38;5;28;01mFalse\u001b[39;00m, normalization=\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m      3\u001b[39m )\n\u001b[32m      4\u001b[39m tokenizer.demoizer = tokenizer.demojizer = \u001b[38;5;28;01mlambda\u001b[39;00m x: demojize(x, language=\u001b[33m\"\u001b[39m\u001b[33mpt\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'AutoTokenizer' is not defined"
     ]
    }
   ],
   "source": [
    "# Load and Setup Tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    MODEL_NAME, do_lower_case=False, normalization=True\n",
    ")\n",
    "tokenizer.demoizer = tokenizer.demojizer = lambda x: demojize(x, language=\"pt\")\n",
    "\n",
    "# Preprocessing Function\n",
    "def preprocess_function(examples):\n",
    "    return tokenizer(examples[\"text\"], truncation=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "851faddf",
   "metadata": {},
   "source": [
    "### Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79002539",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define dataset files\n",
    "train_file = DATA_PATH + 'train.csv'\n",
    "test_file = DATA_PATH +  'test.csv'\n",
    "\n",
    "# Load dataset\n",
    "dataset = load_dataset('csv', data_files={'train': train_file, 'test': test_file})\n",
    "\n",
    "# Rename columns\n",
    "dataset = dataset.rename_column(\"classificacao\", \"label\")\n",
    "\n",
    "# Tokenize dataset\n",
    "tokenized = dataset.map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7661e8c",
   "metadata": {},
   "source": [
    "### Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32388fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Model\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "  MODEL_NAME, \n",
    "  problem_type=\"multi_label_classification\", \n",
    "  num_labels=2, \n",
    "  id2label={0: 'true', 1: 'fake'}, \n",
    "  label2id={'true': 0, 'fake': 1}\n",
    ")\n",
    "\n",
    "# Check if model is using GPU\n",
    "if torch.cuda.is_available():\n",
    "\t\tlogging.info(f\"Model device: {next(model.parameters()).device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d3ba01c",
   "metadata": {},
   "source": [
    "### Fine-tune Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8230e5bc",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unindent does not match any outer indentation level (<string>, line 10)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mFile \u001b[39m\u001b[32m<string>:10\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mlogits, labels = eval_pred\u001b[39m\n                              ^\n\u001b[31mIndentationError\u001b[39m\u001b[31m:\u001b[39m unindent does not match any outer indentation level\n"
     ]
    }
   ],
   "source": [
    "# Metrics Function\n",
    "def compute_metrics(eval_pred):\n",
    "    \"\"\"Compute metrics for the evaluation\"\"\"\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    print(predictions, labels)\n",
    "\n",
    "    clf_metrics = evaluate.combine([\"accuracy\", \"f1\", \"precision\", \"recall\"])\n",
    "    return clf_metrics.compute(predictions=predictions, references=labels)\n",
    "\n",
    "# Training Arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=OUTPUT_PATH,\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=2,\n",
    "    weight_decay=0.01,\n",
    "    eval_strategy=\"epoch\",\n",
    "    do_eval=True,\n",
    "    save_strategy=\"epoch\",\n",
    "    save_total_limit=2,\n",
    "    fp16=True,  # Enable automatic mixed precision.\n",
    ")\n",
    "\n",
    "# Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized[\"train\"],\n",
    "    eval_dataset=tokenized[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=DataCollatorWithPadding(tokenizer=tokenizer),\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "# Train model\n",
    "trainer.train()\n",
    "\n",
    "# Evaluate model\n",
    "trainer.evaluate()\n",
    "\n",
    "# Save model\n",
    "trainer.save_model(OUTPUT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c0ae161",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
